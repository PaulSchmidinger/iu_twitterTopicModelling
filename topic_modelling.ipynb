{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "def createTwDB():\n",
    "    \"\"\"\n",
    "    Creates a consolidated DataFrame from multiple CSV files containing tweet data,\n",
    "    and saves the resulting DataFrame to a CSV file.\n",
    "\n",
    "    Returns:\n",
    "    str: The filename of the saved CSV file containing all the tweets.\n",
    "    \"\"\"\n",
    "    all_files = glob.glob(\"savedTweets/*/*.csv\")\n",
    "\n",
    "    #ceate df from all files\n",
    "    li_tw_files = []\n",
    "    for f in all_files:\n",
    "        df = pd.read_csv(f, index_col=None, header=None, sep=\"\\t\")\n",
    "        li_tw_files.append(df)\n",
    "    df_tw = pd.concat(li_tw_files, axis=0, ignore_index=True)\n",
    "    df_tw.columns = ['id', 'user', 'created_at', 'source', 'in_reply_to_status_id', 'in_reply_to_user_id', 'in_reply_to_screen_name', 'retweet_count', 'text']\n",
    "    df_tw = df_tw.set_index(\"id\")\n",
    "\n",
    "    #save df\n",
    "    filename = \"savedTweets/db_all_tweets.csv\"\n",
    "    df_tw.to_csv(filename, sep=\"\\t\", encoding=\"utf-8\")\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "def extract_hashtags(text):\n",
    "    \"\"\"\n",
    "    Extracts hashtags from the given text.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text from which hashtags will be extracted.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of hashtags found in the given text.\n",
    "    \"\"\"\n",
    "\n",
    "    return re.findall(r'#\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tweet-database\n",
    "csv_tweets = createTwDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe from tweet-database\n",
    "df_all_tweets = pd.read_csv(csv_tweets, sep = '\\t', encoding = 'utf-8')\n",
    "df_all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select relevant columns and preprocess text\n",
    "df_tweets = df_all_tweets[['id','user','text']]\n",
    "df_tweets['text'] = df_tweets['text'].str.lower()\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count tweets per user\t\n",
    "df_tweets_count = df_tweets[['id','user']].groupby('user').count().sort_values(by='id',ascending=False)\n",
    "df_tweets_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract hashtags\n",
    "df_tweets['hashtags'] = df_tweets['text'].apply(extract_hashtags)\n",
    "li_hashtags=[item for sublist in df_tweets['hashtags'].tolist() for item in sublist]\n",
    "df_hashtags = pd.DataFrame(li_hashtags, columns=['hashtag'])\n",
    "\n",
    "#count hashtags\n",
    "df_hashtags_count = df_hashtags.groupby('hashtag').size().sort_values(ascending=False)\n",
    "df_hashtags_count = df_hashtags_count.drop('#imzentrum')\n",
    "df_hashtags_count.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brief discussion on the implications for Topic Modeling:**\n",
    "\n",
    "- Given the prominence of health-related hashtags, it is reasonable to expect that health-related topics, especially those related to COVID-19, may dominate the discussions.\n",
    "- Political topics, particularly those associated with the Austrian People's Party (#övp) and specific figures like August Wöginger, may also be significant. The hashtags regarding the ORF (Austrian Broadcasting Corporation) such as #zib2 refer to the fact, that the ZIB2 is the news show just before ImZentrum.\n",
    "- The variety of hashtags suggests a diverse range of topics, which could make topic modeling more challenging.\n",
    "\n",
    "-> This leads to the decision to remove hashtags and mentions from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download stopwords\n",
    "nltk.download('stopwords')\n",
    "german_stopwords = nltk.corpus.stopwords.words('german')\n",
    "\n",
    "#add elements to stopwords\n",
    "url_elements = [\"co\", \"https co\", \"https\", \"http\", \"www\", \"imzentrum\"]\n",
    "german_stopwords.extend(url_elements)\n",
    "\n",
    "#delete hastags and mentions from text\n",
    "df_tweets['text'] = df_tweets['text'].str.replace(r'@\\S+', '')\n",
    "df_tweets['text'] = df_tweets['text'].str.replace(r'#\\S+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "vectorizer_model = CountVectorizer(stop_words=german_stopwords)\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# Create the model\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,\n",
    "  umap_model=umap_model,\n",
    "  hdbscan_model=hdbscan_model,\n",
    "  vectorizer_model=vectorizer_model,\n",
    "  ctfidf_model=ctfidf_model,\n",
    "  calculate_probabilities=True,        \n",
    "  verbose=True,\n",
    "  language=\"german\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to data\n",
    "topics, _ = topic_model.fit_transform(df_tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity heatmap\n",
    "topic_model.visualize_heatmap(top_n_topics=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity matrix\n",
    "sim_matrix = cosine_similarity(topic_model.c_tf_idf_)\n",
    "df_sim = pd.DataFrame(sim_matrix, columns=topic_model.topic_labels_.values(), index=topic_model.topic_labels_.values())\n",
    "df_sim = df_sim.stack().reset_index().sort_values(0, ascending=False)\n",
    "df_sim.columns = ['Topic 1', 'Topic 2', 'Similarity']\n",
    "\n",
    "#select where Topic 1 != Topic 2 AND Similarity > 0.65\n",
    "df_sim = df_sim[(df_sim['Topic 1'] != df_sim['Topic 2']) & (df_sim['Similarity'] > 0.65)]\n",
    "df_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge topics\n",
    "topics_to_merge = [[150,20],[135,29]]\n",
    "topic_model.merge_topics(df_tweets['text'], topics_to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further reduce topics\n",
    "topic_model.reduce_topics(df_tweets['text'], nr_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize topics\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize topics as a barchart\n",
    "topic_model.visualize_barchart(top_n_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort topics by frequency\n",
    "df_topics = topic_model.get_topic_info()\n",
    "df_topics = df_topics.sort_values('Count', ascending=False)\n",
    "df_topics.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided topic modeling results showcase the most prevalent topics derived from the tweets related to the Austrian public TV show \"Im Zentrum\" and the hashtag #imzentrum during the specified timeframe. Let's briefly discuss each identified topic:\n",
    "\n",
    "1. **Topic 1: Political Representation and Pandemic Response**\n",
    "   - Keywords: ['rt', 'petrovic', 'övp', 'pandemie', 'kurz', 'heute', 'orfimzentrum', 'warum', 'politik', 'arminwolf']\n",
    "   - Representative Documents: A sample includes tweets from Armin Wolf discussing the mandatory smallpox vaccination and political aspects.\n",
    "   - Interpretation: This topic revolves around political representation, with a focus on figures like Petrovic and ÖVP, and discussions about the pandemic response. Armin Wolf's involvement suggests discussions on the political landscape and decision-making during the pandemic.\n",
    "\n",
    "2. **Topic 2: Criticism of ORF and Impfpflicht (Vaccination Obligation)**\n",
    "   - Keywords: ['rt', 'orf', 'ja', 'schon', 'immer', 'mehr', 'heute', 'impfpflicht', 'reiterec', 'frau']\n",
    "   - Representative Documents: Tweets expressing criticism toward ORF, questioning the need for certain guests, and discussing the topic of vaccination obligation.\n",
    "   - Interpretation: This topic reflects public sentiments critical of ORF's choices in guests and discussions surrounding the vaccination obligation. There seems to be disagreement or dissatisfaction with the show's content.\n",
    "\n",
    "3. **Topic 3: Long COVID and Neurological Perspectives**\n",
    "   - Keywords: ['neurostingl', 'milde', 'verläufe', 'neurologe', 'long', 'covid', 'longcovid', 'asymptomatis', 'nutzen', 'langzeitfolgen']\n",
    "   - Representative Documents: Tweets featuring a neurologist emphasizing the long-term effects of mild COVID-19 cases and the impact on asymptomatic individuals.\n",
    "   - Interpretation: This topic centers around the neurological aspects of COVID-19, particularly long COVID. The discussion includes insights from a neurologist and highlights the importance of considering long-term consequences, even in mild cases.\n",
    "\n",
    "4. **Topic 4: Critique of Virus Response and Impfpflicht (Vaccination Obligation)**\n",
    "   - Keywords: ['impfpflicht', 'impfung', 'virus', 'rt', 'verschiedene', 'niemanden', 'schützt', 'lieber', 'beschäftig', 'überrascht']\n",
    "   - Representative Documents: Tweets critiquing the response to the virus, questioning the effectiveness of various vaccines, and criticizing the focus on vaccination obligation.\n",
    "   - Interpretation: This topic involves skepticism and criticism related to the virus response, vaccine efficacy, and the idea of vaccination obligation. The tweets suggest a discussion around the perceived shortcomings in addressing the pandemic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
